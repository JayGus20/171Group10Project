{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3975cfe6",
   "metadata": {},
   "source": [
    "# Anime Recommendation System Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "293017f2",
   "metadata": {},
   "source": [
    "## Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255b86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75356d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "#from sklearn.preprocessing import MinMaxScalerort sklearn as skl\n",
    "\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6365d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.prediction_algorithms import knns\n",
    "from surprise.prediction_algorithms import SVD\n",
    "from surprise.similarities import cosine, msd, pearson\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb692f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession ,Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import StructType,StructField,IntegerType\n",
    "\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12b92884",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "834d8b2d",
   "metadata": {},
   "source": [
    "#### Main Anime Dataset (anime.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5214f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_main = pd.read_csv(\"data/anime.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7068e1f",
   "metadata": {},
   "source": [
    "#### Anime Ratings Dataset (rating_complete.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fc7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_ratings = pd.read_csv(\"data/rating_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anime_main.shape)\n",
    "print(anime_main.columns.unique())\n",
    "anime_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anime_ratings.shape)\n",
    "print(anime_ratings.columns.unique())\n",
    "anime_ratings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f7eb822",
   "metadata": {},
   "source": [
    "## Dataset Cleaning and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70a5364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17562, 6)\n",
      "Index(['MAL_ID', 'Name', 'Score', 'Genres', 'Type', 'Episodes'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.78</td>\n",
       "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
       "      <td>TV</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>8.39</td>\n",
       "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>8.24</td>\n",
       "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
       "      <td>TV</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>7.27</td>\n",
       "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
       "      <td>TV</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>6.98</td>\n",
       "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
       "      <td>TV</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAL_ID                             Name Score  \\\n",
       "0       1                     Cowboy Bebop  8.78   \n",
       "1       5  Cowboy Bebop: Tengoku no Tobira  8.39   \n",
       "2       6                           Trigun  8.24   \n",
       "3       7               Witch Hunter Robin  7.27   \n",
       "4       8                   Bouken Ou Beet  6.98   \n",
       "\n",
       "                                              Genres   Type Episodes  \n",
       "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space     TV       26  \n",
       "1              Action, Drama, Mystery, Sci-Fi, Space  Movie        1  \n",
       "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen     TV       26  \n",
       "3  Action, Mystery, Police, Supernatural, Drama, ...     TV       26  \n",
       "4          Adventure, Fantasy, Shounen, Supernatural     TV       52  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean main anime dataset and keep necessary features\n",
    "anime_main = anime_main[['MAL_ID', 'Name', 'Score', 'Genres', 'Type', 'Episodes']]\n",
    "anime_main.dropna(inplace=True)\n",
    "\n",
    "print(anime_main.shape)\n",
    "print(anime_main.columns)\n",
    "anime_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda1f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and merge datasets\n",
    "anime_main = anime_main.rename(columns={'MAL_ID': 'Anime ID'})\n",
    "anime_ratings = anime_ratings.rename(columns={'user_id': 'User ID', 'anime_id': 'Anime ID', 'rating': 'Rating'})\n",
    "anime_df = pd.merge(anime_main, anime_ratings, on='Anime ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3777f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anime_df.shape)\n",
    "print(anime_df.columns)\n",
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af8939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_sample = anime_df.sample(n=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b34225c4",
   "metadata": {},
   "source": [
    "CSV for mapping Name to ID (app.py use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc1b9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv for mapping name to ID\n",
    "animeName_id_df = anime_main[['Anime ID', 'Name']]\n",
    "animeName_id_df.to_csv('data/id_to_name.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fad0cbd6",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Type', data=anime_main, color='cyan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "452bdeaf",
   "metadata": {},
   "source": [
    "OVA = Original Video Animation, ONA = Original Net Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a999960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Rating', data=anime_ratings, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ed40b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Comedy', 'Slice of Life', 'Drama',\n",
       "       'Sci-Fi', 'Samurai', 'Game', 'Harem', 'Military', 'Space', 'Music',\n",
       "       'Mecha', 'Supernatural', 'Historical', 'Mystery', 'School',\n",
       "       'Hentai', 'Fantasy', 'Ecchi', 'Horror', 'Kids', 'Sports',\n",
       "       'Dementia', 'Magic', 'Romance', 'Police', 'Psychological', 'Cars',\n",
       "       'Shounen', 'Demons', 'Parody', 'Shoujo', 'Super Power', 'Vampire',\n",
       "       'Martial Arts', 'Seinen', 'Yaoi', 'Thriller', 'Josei', 'Unknown',\n",
       "       'Shounen Ai', ' Adventure', ' Drama', ' Sci-Fi', ' Mystery',\n",
       "       ' Fantasy', ' Sports', ' Comedy', ' Cars', ' Horror', ' Shounen',\n",
       "       ' Romance', ' Supernatural', ' Military', ' Mecha', ' Dementia',\n",
       "       ' Historical', ' Magic', ' Slice of Life', ' Demons', ' Harem',\n",
       "       ' School', ' Ecchi', ' Psychological', ' Game', ' Super Power',\n",
       "       ' Hentai', None, ' Parody', ' Music', ' Space', ' Shoujo',\n",
       "       ' Josei', ' Seinen', ' Samurai', ' Martial Arts', ' Police',\n",
       "       ' Kids', ' Shounen Ai', ' Yaoi', ' Yuri', ' Vampire', ' Shoujo Ai',\n",
       "       ' Thriller', ' Romdokance'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique Genre values\n",
    "genres = anime_main['Genres']\n",
    "genres = pd.DataFrame([sub.split(\",\") for sub in genres])\n",
    "pd.unique(genres.values.ravel('K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b872c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ID to name dictionary\n",
    "def read_item_names():\n",
    "    file_name = \"data/anime.csv\"\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with open(file_name, encoding=\"ISO-8859-1\") as f:\n",
    "        # skip header line\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            line = line.split(\",\")\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid\n",
    "\n",
    "rid_to_name, name_to_rid = read_item_names()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bec2aff",
   "metadata": {},
   "source": [
    "## Grid Search / SVD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b4af08e",
   "metadata": {},
   "source": [
    "Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample subset of data\n",
    "svd_anime_sample = anime_df.sample(n=5000)\n",
    "svd_anime_sample = svd_anime_sample[['User ID', 'Anime ID', 'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e964a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_df(df):\n",
    "    reader = Reader(rating_scale=(1,10))\n",
    "    return Dataset.load_from_df(df, reader)\n",
    "\n",
    "# Read into Suprise dataset\n",
    "svd_ratings_dataset =create_dataset_from_df(svd_anime_sample)\n",
    "svd_ratings_dataset = Dataset.load_from_df(svd_anime_sample, reader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42a59f52",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal hyperparameters\n",
    "param_grid = {\n",
    "    'lr_all' : [.05, .01],\n",
    "    'n_factors' : [50, 75, 100],\n",
    "    'reg_all': [.05,.1],\n",
    "    'n_epochs' : [50, 100, 150]\n",
    "}\n",
    "gridsearch_svd = GridSearchCV(\n",
    "    SVD, \n",
    "    param_grid = param_grid, \n",
    "    n_jobs = -1, \n",
    "    joblib_verbose = 3)\n",
    "\n",
    "gridsearch_svd.fit(svd_ratings_dataset)\n",
    "\n",
    "print(gridsearch_svd.best_score)\n",
    "print(gridsearch_svd.best_params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25117fd",
   "metadata": {},
   "source": [
    "Training Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aacd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance from grid search optimal hyperparameters\n",
    "svd_instance = gridsearch_svd.best_estimator[\"rmse\"]\n",
    "# Print Params\n",
    "# print(svd_instance.__dict__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a779bcb",
   "metadata": {},
   "source": [
    "Basic SVD Rating Prediction Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb276c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appends a new user to the df for refitting and predicting\n",
    "# We need to do this because suprise does not support iterative training with SVD\n",
    "def create_predict_dataset(base_df, anime_ids, ratings):\n",
    "    predictor_df = base_df.copy()\n",
    "    for i in range(len(anime_ids)):\n",
    "        predictor_df.loc[len(predictor_df)] = [-1,anime_ids[i], ratings[i]]\n",
    "    \n",
    "    return create_dataset_from_df(predictor_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bbf481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Displays predictions for some user ID\n",
    "# TODO: Should display name of anime\n",
    "def show_predictions(model_instance, user_id, anime_ids, ratings_df):\n",
    "    for anime_id in anime_ids:\n",
    "        condition = (ratings_df['User ID'] == user_id) & (ratings_df['Anime ID'] == anime_id)\n",
    "        model_instance.predict(\n",
    "            user_id, \n",
    "            anime_id, \n",
    "            #ratings_df.loc[condition, 'Rating'],\n",
    "            verbose = True)\n",
    "\n",
    "# Creates a dataframe for the predictions\n",
    "def get_predictions(model_instance, user_id, anime_ids):\n",
    "\n",
    "    predict_ratings = pd.DataFrame(columns=['Anime ID', 'Rating'])\n",
    "\n",
    "    # Use suprise model predict method to get predictions\n",
    "    # This only works on userIDs that were in the training set\n",
    "    for anime_id in anime_ids:\n",
    "        prediction = model_instance.predict(\n",
    "            user_id, \n",
    "            anime_id)\n",
    "\n",
    "        predict_ratings.loc[len(predict_ratings)] = [anime_id, prediction.est]\n",
    "\n",
    "    return predict_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbe8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anime_ratings[anime_ratings['User ID'] == 35])\n",
    "show_predictions(svd_instance, 35, [64, 6707, 6547, 4898], svd_anime_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7321245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions for a mew user provided their anime ratings\n",
    "# This refits the entire model with the new user appended onto the base df with a user ID of -1\n",
    "\n",
    "def create_predictions_for_user(model_instance, base_df, anime_ids, ratings):\n",
    "\n",
    "    # Create suprise dataset with new user\n",
    "    predict_dataset = create_predict_dataset(\n",
    "        base_df, \n",
    "        anime_ids,\n",
    "        ratings)\n",
    "\n",
    "    # Train on entire dataset\n",
    "    # TODO: Should we do this?\n",
    "    model_instance.fit(predict_dataset.build_full_trainset())\n",
    "    # model_instance.fit(full_trainset)\n",
    "\n",
    "    # Create a series of all the anime IDs that want to be predicted (all of them, more or less)\n",
    "    predict_anime_ids = base_df['Anime ID'];\n",
    "    predict_anime_ids = predict_anime_ids.append(pd.Series(anime_ids)).unique()\n",
    "    \n",
    "    # Show predictions for the known ratings\n",
    "    show_predictions(model_instance, -1, anime_ids, svd_anime_sample)\n",
    "\n",
    "    # Generate and return predictions for all the anime\n",
    "    return get_predictions(model_instance, -1, predict_anime_ids)\n",
    "\n",
    "# Print out information for top N predictions\n",
    "def display_top_n(predictions, n):\n",
    "    # Sort descending\n",
    "    predictions = predictions.sort_values('Rating', ascending=False)\n",
    "    \n",
    "    print(predictions)\n",
    "    print(\"Top {} predicted scores\".format(n))\n",
    "    # Print information about top n\n",
    "    for index, row in predictions.head(n).iterrows():\n",
    "        anime_id = row['Anime ID']\n",
    "        rating = row['Rating']\n",
    "        name = rid_to_name[str(int(anime_id))]\n",
    "        print(\"Anime: {} Rating: {} Name: {}\".format(anime_id, rating, name))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfb1c432",
   "metadata": {},
   "source": [
    "Tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fbdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User 1 \n",
    "# Drama / romance\n",
    "\n",
    "user_1_anime_ids = [4224, 23273, 1723, 32281, 37450, 2167, 121]\n",
    "user_1_ratings = [10, 8, 9, 9, 10, 9, 4]\n",
    "\n",
    "# No randomness between each fit\n",
    "svd_instance.random_state = 1\n",
    "\n",
    "user_1_predictions = create_predictions_for_user(\n",
    "    svd_instance,\n",
    "    svd_anime_sample,\n",
    "    user_1_anime_ids,\n",
    "    user_1_ratings\n",
    "    )\n",
    "\n",
    "display_top_n(user_1_predictions, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46925b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User 1 \n",
    "# Action / Adventure\n",
    "user_2_pred = create_predictions_for_user(\n",
    "    svd_instance,\n",
    "    svd_anime_sample,\n",
    "    [114, 31964, 32051, 34134, 38000],\n",
    "    [9, 10, 8, 9, 9]\n",
    "    )\n",
    "\n",
    "display_top_n(user_2_pred, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd311ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User 3 \n",
    "# Boys Love\n",
    "user_3_anime_ids = [114, 31964, 32051, 34134, 38000, 39533, 30346, 44055, 918]\n",
    "user_3_ratings = [4, 5, 4, 6, 4, 10, 10, 9, 4]\n",
    "\n",
    "user_3_predictions = create_predictions_for_user(\n",
    "    svd_instance,\n",
    "    svd_anime_sample,\n",
    "    user_3_anime_ids,\n",
    "    user_3_ratings\n",
    ")\n",
    "\n",
    "display_top_n(user_3_predictions, 25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a92fea38",
   "metadata": {},
   "source": [
    "Older SVD Stuff idk what this does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4145fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# def get_top_n(predictions, n = 10):\n",
    "#     top_n = defaultdict(list)\n",
    "#     for uid, iid, true_r, est, _ in predictions:\n",
    "#         top_n[uid].append((iid, est))\n",
    "\n",
    "#     # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "#     for uid, user_ratings in top_n.items():\n",
    "#         user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "#         top_n[uid] = user_ratings[:n]\n",
    "\n",
    "#     return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_anime = get_top_n(anime_predictions,n=10)\n",
    "\n",
    "# for uid, user_ratings in top_anime.items():\n",
    "#     if len([iid for (iid, _) in user_ratings]) == 10:\n",
    "#         print(uid, [iid for (iid, _) in user_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id = -1\n",
    "# anime_ids = []\n",
    "# for uid, user_ratings in top_anime.items():\n",
    "#     if len([iid for (iid, _) in user_ratings]) == 10:\n",
    "#         user_id = uid\n",
    "#         anime_ids = [iid for (iid, _) in user_ratings]\n",
    "#         break\n",
    "# print(user_id, anime_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for anime_id in anime_ids:\n",
    "#     print(anime_main.loc[anime_main['Anime ID'] == anime_id]['Name'].to_string(index=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83648f46",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "733fbe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_anime_sample = anime_df.sample(n=5000)[['User ID', 'Anime ID', 'Rating']]\n",
    "\n",
    "reader = Reader(line_format = 'user item rating', sep='')\n",
    "knn_anime_data = Dataset.load_from_df(knn_anime_sample, reader)\n",
    "\n",
    "knn_anime_trainset = knn_anime_data.build_full_trainset()\n",
    "knn_anime_testset = knn_anime_trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b38078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "simulation_variables = {\"Name\" : \"pearson_baseline\", \"user_based\" : False}\n",
    "knn_baseline = KNNBaseline(sim_options = simulation_variables)\n",
    "knn_baseline.fit(knn_anime_trainset)\n",
    "\n",
    "anime_name = \"Cowboy Bebop\"\n",
    "anime_raw_id = int(name_to_rid[anime_name])\n",
    "anime_inner_id = knn_baseline.trainset.to_inner_iid(anime_raw_id)\n",
    "\n",
    "anime_neighbors = knn_baseline.get_neighbors(anime_inner_id, k=10)\n",
    "\n",
    "anime_neighbors = (\n",
    "    knn_baseline.trainset.to_raw_iid(inner_id) for inner_id in anime_neighbors\n",
    ")\n",
    "\n",
    "anime_neighbors = (rid_to_name[str(rid)] for rid in anime_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71a7fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 nearest neighbors of Cowboy Bebop are:\n",
      "Nisekoi\n",
      "Bokusatsu Tenshi Dokuro-chan\n",
      "Cheonnyeon-yeowoo Yeowoobi\n",
      "High School DxD OVA\n",
      "Toaru Kagaku no Railgun: Motto Marutto Railgun\n",
      "Gangsta.\n",
      "Log Horizon 2nd Season\n",
      "Suzumiya Haruhi no Yuuutsu\n",
      "Walkure Romanze\n",
      "Tsurezure Children\n"
     ]
    }
   ],
   "source": [
    "print(\"The 10 nearest neighbors of\", anime_name, \"are:\")\n",
    "for anime in anime_neighbors:\n",
    "    print(anime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eafe5dd",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa04602",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_basic = KNNBasic(sim_options = {'name':'pearson','user_based':True})\n",
    "\n",
    "cv_knn_baseline = cross_validate(knn_basic, knn_anime_data, n_jobs=-1)\n",
    "print(np.mean(cv_knn_baseline['test_rmse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5968a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([2.98546479, 2.99583044, 2.96293773, 3.05908483, 2.95059316]),\n",
       " 'test_mae': array([2.645, 2.657, 2.607, 2.73 , 2.614]),\n",
       " 'fit_time': (0.43232035636901855,\n",
       "  0.4418449401855469,\n",
       "  0.41533398628234863,\n",
       "  0.4521176815032959,\n",
       "  0.4691200256347656),\n",
       " 'test_time': (0.0075299739837646484,\n",
       "  0.0059986114501953125,\n",
       "  0.00792551040649414,\n",
       "  0.006028175354003906,\n",
       "  0.006009578704833984)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_knn_baseline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36b4778b",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863622d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(knn_baseline, open('knn_model.pkl','wb')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
